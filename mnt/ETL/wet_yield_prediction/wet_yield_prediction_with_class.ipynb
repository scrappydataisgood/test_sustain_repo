{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c29843b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.22.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.24.2 in /opt/conda/lib/python3.9/site-packages (from mlxtend) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /opt/conda/lib/python3.9/site-packages (from mlxtend) (1.8.0)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from mlxtend) (3.5.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /opt/conda/lib/python3.9/site-packages (from mlxtend) (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /opt/conda/lib/python3.9/site-packages (from mlxtend) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /opt/conda/lib/python3.9/site-packages (from mlxtend) (1.21.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from mlxtend) (65.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (4.37.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (9.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=0.24.2->mlxtend) (2022.2.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=1.0.2->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.22.0\n",
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.9/site-packages (3.3.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from lightgbm) (1.21.6)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.9/site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/lib/python3.9/site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from lightgbm) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from xgboost) (1.21.6)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from xgboost) (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend --user\n",
    "!pip install lightgbm --user\n",
    "!pip install xgboost --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0344cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy as sp\n",
    "import math\n",
    "import random\n",
    "import seaborn as sn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import sklearn.linear_model as linear_model\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668cfb95",
   "metadata": {},
   "source": [
    "# Importing the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d993dcb8",
   "metadata": {},
   "source": [
    "## Model Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a14565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(np.mean((y - y_pred)**2))\n",
    "\n",
    "def mae(y, y_pred):\n",
    "    return np.mean(np.absolute(np.subtract(y, y_pred)))\n",
    "\n",
    "def r2(y, y_pred):\n",
    "    return 1 - np.sum((y - y_pred)**2)/np.sum((y - np.mean(y))**2)\n",
    "\n",
    "def mape(y, y_pred):\n",
    "    return (np.mean(np.divide(np.absolute(np.subtract(y,y_pred)), y))*100)\n",
    "\n",
    "def errors(y, y_pred):\n",
    "    return np.absolute(y - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288bb133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winter = pd.read_csv('/mnt/ETL/Datasets/yield_prediction_dataset.csv').drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2159d22",
   "metadata": {},
   "source": [
    "## Using a Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "514b083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictorWithScalars:\n",
    "    \n",
    "    def __init__(self, predictor, X_scalar, X_transformer, y_scalar, y_transformer):\n",
    "        self.predictor = predictor\n",
    "        self.X_scalar = X_scalar\n",
    "        self.X_transformer = X_transformer\n",
    "        self.y_scalar = y_scalar\n",
    "        self.y_transformer = y_transformer\n",
    "    \n",
    "    def transform_X(self, X):\n",
    "        transformed_X = self.X_transformer.transform(self.X_scalar.transform(X))\n",
    "        return transformed_X\n",
    "    \n",
    "    def transform_y(self, y):\n",
    "        transformed_y = self.y_transformer.transform(self.y_scalar.transform(y))\n",
    "        return transformed_y\n",
    "\n",
    "    def predict(self, X):\n",
    "        transformed_X = self.X_transformer.transform(self.X_scalar.transform(X))\n",
    "        transformed_y_preds = self.predictor.predict(transformed_X).reshape(-1,1)\n",
    "        inverse_transformed_y_preds = self.y_scalar.inverse_transform(self.y_transformer.inverse_transform(transformed_y_preds))\n",
    "        return inverse_transformed_y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09bf5133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dataset, outlier_removal_lower_percentile, seed):\n",
    "    \n",
    "    dataset = dataset[(dataset['Yield_kg_per_Ha'] > dataset['Yield_kg_per_Ha'].quantile(outlier_removal_lower_percentile)) \\\n",
    "                                                                   & (dataset['Yield_kg_per_Ha'] < dataset['Yield_kg_per_Ha'].quantile(1-outlier_removal_lower_percentile))].reset_index(drop = True)\n",
    "\n",
    "    train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(dataset, test_size = 0.18, random_state = seed)\n",
    "\n",
    "    X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "    X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "    y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "    y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "    mean_Yield_kg_per_ha = np.mean(y_train_Yield_kg_per_ha)\n",
    "\n",
    "    standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "    power_transform_X = PowerTransformer(standardize = True).fit(standard_scaler_X.transform(X_train_Yield_kg_per_ha))\n",
    "\n",
    "    standard_scaler_y = StandardScaler().fit(y_train_Yield_kg_per_ha)\n",
    "    power_transform_y = PowerTransformer(standardize = True).fit(standard_scaler_y.transform(y_train_Yield_kg_per_ha))\n",
    "\n",
    "    xgboost = XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                                              colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "\n",
    "    predictorScaler = PredictorWithScalars(xgboost, standard_scaler_X, power_transform_X, standard_scaler_y, power_transform_y)\n",
    "    predictorScaler.predictor = predictorScaler.predictor.fit(predictorScaler.transform_X(X_train_Yield_kg_per_ha), predictorScaler.transform_y(y_train_Yield_kg_per_ha))\n",
    "    \n",
    "    return predictorScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c8190cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(df_winter_combined_parents_final_test_set, model_build_dict):\n",
    "    \n",
    "    y_preds = np.zeros((len(df_winter_combined_parents_final_test_set), len(model_build_dict)))\n",
    "    \n",
    "    for i in range(len(model_build_dict)):\n",
    "\n",
    "        X_df_winter_combined_parents_final_test_set = df_winter_combined_parents_final_test_set.drop(columns = ['Yield_kg_per_Ha'])\n",
    "        y_df_winter_combined_parents_final_test_set = np.array(df_winter_combined_parents_final_test_set['Yield_kg_per_Ha']).reshape(-1,1)\n",
    "        y_preds[:,i] = model_build_dict.get(i).predict(X_df_winter_combined_parents_final_test_set)[:,0]\n",
    "        \n",
    "    final_preds = np.mean(y_preds, axis = 1).reshape(-1,1)\n",
    "    mean_abs_error = mean_absolute_error(y_df_winter_combined_parents_final_test_set, final_preds)\n",
    "    root_mean_sq_error = np.sqrt(mean_squared_error(y_df_winter_combined_parents_final_test_set, final_preds))\n",
    "    r_sq = r2_score(y_df_winter_combined_parents_final_test_set, final_preds)\n",
    "    \n",
    "    return mean_abs_error, root_mean_sq_error, r_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23b2dca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:15:45] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:16:10] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:16:34] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:16:59] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:17:23] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:17:49] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:18:13] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:18:37] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:19:05] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:19:31] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:19:55] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:20:20] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:20:59] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:21:53] WARNING: ../src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "df_winter_combined_parents = pd.read_csv('/mnt/ETL/Datasets/yield_prediction_dataset.csv').drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "num_seeds_list = [5, 5, 5, 5, 5]\n",
    "\n",
    "random_state_list = random.sample(range(1000), len(num_seeds_list))\n",
    "\n",
    "results_collection_df = pd.DataFrame(columns = ['num_models', 'mae', 'rmse', 'r_squared'])\n",
    "\n",
    "for i,num_seeds in enumerate(num_seeds_list):\n",
    "    \n",
    "    df_winter_combined_parents_temp = df_winter_combined_parents.sample(frac = 1, random_state = random_state_list[i]).reset_index(drop = True)\n",
    "    df_winter_combined_parents_final_test_set = df_winter_combined_parents_temp[:57]\n",
    "    df_winter_combined_parents_temp = df_winter_combined_parents_temp[57:].reset_index(drop = True)\n",
    "    \n",
    "    seed_list = random.sample(range(1000), num_seeds)\n",
    "    \n",
    "    model_build_dict = {}\n",
    "    \n",
    "    for i,seed in enumerate(seed_list):\n",
    "        model_build_dict.update({i: build_model(df_winter_combined_parents_temp, 0, seed)})\n",
    "    \n",
    "    eval_model_temp = eval_model(df_winter_combined_parents_final_test_set, model_build_dict)\n",
    "    row = pd.DataFrame({'num_models': [num_seeds], 'mae': [eval_model_temp[0]], 'rmse': [eval_model_temp[1]], 'r_squared': [eval_model_temp[2]]})\n",
    "    \n",
    "    results_collection_df = pd.concat([results_collection_df, row], axis = 0)\n",
    "\n",
    "print(display(results_collection_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc257d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1b9ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db3d6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winter_combined_parents = pd.read_csv('/mnt/ETL/Datasets/yield_prediction_dataset.csv').drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6728f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictorWithScalars:\n",
    "    \n",
    "    def __init__(self, predictor, X_scalar, X_transformer, y_scalar, y_transformer):\n",
    "        self.predictor = predictor\n",
    "        self.X_scalar = X_scalar\n",
    "        self.X_transformer = X_transformer\n",
    "        self.y_scalar = y_scalar\n",
    "        self.y_transformer = y_transformer\n",
    "    \n",
    "    def transform_X(self, X):\n",
    "        transformed_X = self.X_transformer.transform(self.X_scalar.transform(X))\n",
    "        return transformed_X\n",
    "    \n",
    "    def transform_y(self, y):\n",
    "        transformed_y = self.y_transformer.transform(self.y_scalar.transform(y))\n",
    "        return transformed_y\n",
    "\n",
    "    def predict(self, X):\n",
    "        transformed_X = self.X_transformer.transform(self.X_scalar.transform(X))\n",
    "        transformed_y_preds = self.predictor.predict(transformed_X).reshape(-1,1)\n",
    "        inverse_transformed_y_preds = self.y_scalar.inverse_transform(self.y_transformer.inverse_transform(transformed_y_preds))\n",
    "        return inverse_transformed_y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ffe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dataset, outlier_removal_lower_percentile, seed):\n",
    "    \n",
    "    dataset = dataset[(dataset['Yield_kg_per_Ha'] > dataset['Yield_kg_per_Ha'].quantile(outlier_removal_lower_percentile)) \\\n",
    "                                                                   & (dataset['Yield_kg_per_Ha'] < dataset['Yield_kg_per_Ha'].quantile(1-outlier_removal_lower_percentile))].reset_index(drop = True)\n",
    "\n",
    "    train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(dataset, test_size = 0.18, random_state = seed)\n",
    "\n",
    "    X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "    X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "    y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "    y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "    mean_Yield_kg_per_ha = np.mean(y_train_Yield_kg_per_ha)\n",
    "\n",
    "    standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "    power_transform_X = PowerTransformer(standardize = True).fit(standard_scaler_X.transform(X_train_Yield_kg_per_ha))\n",
    "\n",
    "    standard_scaler_y = StandardScaler().fit(y_train_Yield_kg_per_ha)\n",
    "    power_transform_y = PowerTransformer(standardize = True).fit(standard_scaler_y.transform(y_train_Yield_kg_per_ha))\n",
    "\n",
    "    xgboost = XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                                              colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "\n",
    "    predictorScaler = PredictorWithScalars(xgboost, standard_scaler_X, power_transform_X, standard_scaler_y, power_transform_y)\n",
    "    predictorScaler.predictor = predictorScaler.predictor.fit(predictorScaler.transform_X(X_train_Yield_kg_per_ha), predictorScaler.transform_y(y_train_Yield_kg_per_ha))\n",
    "    \n",
    "    return predictorScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e5d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# from sklearn.externals import joblib\n",
    "\n",
    "random.seed(10)\n",
    "random_state_list1 = random.sample(range(1000), 5)\n",
    "\n",
    "random.seed(11)\n",
    "random_state_list2 = random.sample(range(1000), 5)\n",
    "\n",
    "pickle.dump(df_winter_combined_parents, open('/mnt/ETL/Datasets/yield_prediction_dataset.csv', 'wb'))\n",
    "\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents.sample(frac = 1, random_state = random_state_list1[0]).reset_index(drop = True)\n",
    "df_winter_combined_parents_final_test_set = df_winter_combined_parents_temp[:57]\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents_temp[57:].reset_index(drop = True)\n",
    "\n",
    "predictor_scaler1 = build_model(df_winter_combined_parents_temp, 0, random_state_list2[0])\n",
    "pickle.dump(predictor_scaler1.X_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Scalar_1_yield.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler1.y_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_Scalar_1_yield.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler1.X_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Transformer_1_yield.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler1.y_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_transformer_1_yield.pkl', \"wb\"))\n",
    "pickle.dump(predictor_scaler1.predictor, open(\"/mnt/ETL/pkl_predictors_scalars_transformers/predictor_111_yield.pkl\", \"wb\"))\n",
    "\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents.sample(frac = 1, random_state = random_state_list1[0]).reset_index(drop = True)\n",
    "df_winter_combined_parents_final_test_set = df_winter_combined_parents_temp[:57]\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents_temp[57:].reset_index(drop = True)\n",
    "predictor_scaler2 = build_model(df_winter_combined_parents_temp, 0, random_state_list2[1])\n",
    "pickle.dump(predictor_scaler2.X_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Scalar_2_yield.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler2.y_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_Scalar_2_yield.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler2.X_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Transformer_2_yield.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler2.y_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_transformer_2_yield.pkl', \"wb\"))\n",
    "pickle.dump(predictor_scaler2.predictor, open(\"/mnt/ETL/pkl_predictors_scalars_transformers/predictor_222_yield.pkl\", \"wb\"))\n",
    "\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents.sample(frac = 1, random_state = random_state_list1[0]).reset_index(drop = True)\n",
    "df_winter_combined_parents_final_test_set = df_winter_combined_parents_temp[:57]\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents_temp[57:].reset_index(drop = True)\n",
    "predictor_scaler3 = build_model(df_winter_combined_parents_temp, 0, random_state_list2[2])\n",
    "pickle.dump(predictor_scaler3.X_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Scalar_3_yield.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler3.y_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_Scalar_3_yield.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler3.X_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Transformer_3_yield.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler3.y_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_transformer_3_yield.pkl', \"wb\"))\n",
    "pickle.dump(predictor_scaler3.predictor, open(\"/mnt/ETL/pkl_predictors_scalars_transformers/predictor_333_yield.pkl\", \"wb\"))\n",
    "\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents.sample(frac = 1, random_state = random_state_list1[0]).reset_index(drop = True)\n",
    "df_winter_combined_parents_final_test_set = df_winter_combined_parents_temp[:57]\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents_temp[57:].reset_index(drop = True)\n",
    "predictor_scaler4 = build_model(df_winter_combined_parents_temp, 0, random_state_list2[3])\n",
    "pickle.dump(predictor_scaler4.X_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Scalar_4_yield.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler4.y_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_Scalar_4_yield.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler4.X_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Transformer_4_yield.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler4.y_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_transformer_4_yield.pkl', \"wb\"))\n",
    "pickle.dump(predictor_scaler4.predictor, open(\"/mnt/ETL/pkl_predictors_scalars_transformers/predictor_444_yield.pkl\", \"wb\"))\n",
    "\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents.sample(frac = 1, random_state = random_state_list1[0]).reset_index(drop = True)\n",
    "df_winter_combined_parents_final_test_set = df_winter_combined_parents_temp[:57]\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents_temp[57:].reset_index(drop = True)\n",
    "predictor_scaler5 = build_model(df_winter_combined_parents_temp, 0, random_state_list2[4])\n",
    "pickle.dump(predictor_scaler5.X_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Scalar_5_yield.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler5.y_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_Scalar_5_yield.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler5.X_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Transformer_5_yield.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler5.y_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_transformer_5_yield.pkl', \"wb\"))\n",
    "pickle.dump(predictor_scaler5.predictor, open(\"/mnt/ETL/pkl_predictors_scalars_transformers/predictor_555_yield.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df1376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d3dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
