{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f0873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install mlxtend --user\n",
    "!pip install lightgbm --user\n",
    "!pip install xgboost --user\n",
    "!pip install plotly --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5200af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import math\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import sklearn.linear_model as linear_model\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ecb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(np.mean((y - y_pred)**2))\n",
    "\n",
    "def mae(y, y_pred):\n",
    "    return np.mean(np.absolute(np.subtract(y, y_pred)))\n",
    "\n",
    "def r2(y, y_pred):\n",
    "    return 1 - np.sum((y - y_pred)**2)/np.sum((y - np.mean(y))**2)\n",
    "\n",
    "def mape(y, y_pred):\n",
    "    return (np.mean(np.divide(np.absolute(np.subtract(y,y_pred)), y))*100)\n",
    "\n",
    "def errors(y, y_pred):\n",
    "    return np.absolute(y - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4c7f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summer, parent compounds\n",
    "\n",
    "##Subsetting order:\n",
    "#K as Potassium\n",
    "#N as Ammonium\n",
    "#N as nitrate\n",
    "#N as urea\n",
    "#K as K2O\n",
    "#P as phosphorus\n",
    "#P as P2O5\n",
    "#Soil Organic Matter\n",
    "#Crop Protection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4dbc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#N_as_Ammonium Summer Results:\n",
    "#1.Visual inspection N_as_Ammonium >= 30 XGBoost had good results\n",
    "#2. XGBoost cluster 0 had good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c6b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "plt.figure(figsize=(8,5))\n",
    "df['N_as_Nitrate_kg_per_Ha'].hist(bins = 20)\n",
    "plt.show()\n",
    "\n",
    "#Visually, Separate 0 and non-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a94a35e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#N_as_Nitrate = 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_N_0 = df[df['N_as_Nitrate_kg_per_Ha'] == 0].reset_index(drop = True)\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_N_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41faa82f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#N_as_Nitrate != 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_N_not_0 = df[df['N_as_Nitrate_kg_per_Ha'] != 0].reset_index(drop = True)\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_N_not_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d7b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summer\n",
    "#Elbow method N as Nitrate\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "sum_of_squared_distances = []\n",
    "for k in range(1,11):\n",
    "    kmeans = KMeans(n_clusters = k)\n",
    "    kmeans.fit(df['N_as_Nitrate_kg_per_Ha'].values.reshape(-1,1))\n",
    "    sum_of_squared_distances.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1,11), sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('Num Clusters')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['N_as_Nitrate_kg_per_Ha'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e7eaa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#N_as_Nitrate Cluster 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['N_as_Nitrate_kg_per_Ha'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_N_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_N_cluster_0 = df_N_cluster_0.drop(columns = ['cluster'])\n",
    "print(display(df_N_cluster_0))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_N_cluster_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d832d2aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#N_as_Nitrate Cluster 1\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['N_as_Nitrate_kg_per_Ha'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_N_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_N_cluster_1 = df_N_cluster_1.drop(columns = ['cluster'])\n",
    "print(display(df_N_cluster_1))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_N_cluster_1, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe12aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#N_as_Nitrate Summer Results:\n",
    "#1.No good models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b9df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "plt.figure(figsize=(8,5))\n",
    "df['Soil_Organic_Matter'].hist(bins = 20)\n",
    "plt.show()\n",
    "\n",
    "#Visually, separate above 3 and below 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794aecc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#Soil_Organic_Matter < 3\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_low = df[df['Soil_Organic_Matter'] < 3].reset_index(drop = True)\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_low, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef408273",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#Soil_Organic_Matter >= 3\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_high = df[df['Soil_Organic_Matter'] >= 3].reset_index(drop = True)\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_high, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b80230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summer\n",
    "#Elbow method Soil Organic Matter\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "sum_of_squared_distances = []\n",
    "for k in range(1,11):\n",
    "    kmeans = KMeans(n_clusters = k)\n",
    "    kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "    sum_of_squared_distances.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1,11), sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('Num Clusters')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d19ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#Soil_Organic_Matter Cluster 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\n",
    "print(display(df_SOM_cluster_0))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fa0a22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#Soil_Organic_Matter Cluster 1\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1.drop(columns = ['cluster'])\n",
    "print(display(df_SOM_cluster_1))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_1, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soil_Organic_Matter Summer Results:\n",
    "#1.XGBoost Cluster 0 had good prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03fe6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada8a707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df2411d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc76974e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9895e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a8c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe57c77f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf013b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795a2886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ffefd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1888e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Winter\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "plt.figure(figsize=(8,5))\n",
    "df['Soil_Organic_Matter'].hist(bins = 20)\n",
    "plt.show()\n",
    "\n",
    "#Visually, separate above 3 and below 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cbc498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Winter\n",
    "#Soil_Organic_Matter < 3\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_low = df[df['Soil_Organic_Matter'] < 3].reset_index(drop = True)\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_low, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78636379",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Winter\n",
    "#Soil_Organic_Matter >= 3\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_high = df[df['Soil_Organic_Matter'] >= 3].reset_index(drop = True)\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_high, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d396d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Winter\n",
    "#Elbow method Soil Organic Matter\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "sum_of_squared_distances = []\n",
    "for k in range(1,11):\n",
    "    kmeans = KMeans(n_clusters = k)\n",
    "    kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "    sum_of_squared_distances.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1,11), sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('Num Clusters')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce75eb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Winter\n",
    "#Soil_Organic_Matter Cluster 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\n",
    "print(display(df_SOM_cluster_0))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f16f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Winter\n",
    "#Soil_Organic_Matter Cluster 1\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1.drop(columns = ['cluster'])\n",
    "print(display(df_SOM_cluster_1))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_1, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a098c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soil_Organic_Matter Winter Results:\n",
    "#1.XGBoost Cluster 0 had good prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9578a86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae948e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summer, elements combined (SOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fc9209",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#Soil_Organic_Matter Cluster 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_combined_elements.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\n",
    "print(display(df_SOM_cluster_0))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48834734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#Soil_Organic_Matter Cluster 1\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_combined_elements.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1.drop(columns = ['cluster'])\n",
    "print(display(df_SOM_cluster_1))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_1, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4be2c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soil_Organic_Matter Summer Combined Elements Results:\n",
    "#1.No good prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872649a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Winter Elements Combined\n",
    "#Soil_Organic_Matter Cluster 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_combined_elements.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\n",
    "print(display(df_SOM_cluster_0))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c287ffef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Winter Elements Combined\n",
    "#Soil_Organic_Matter Cluster 1\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_combined_elements.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1.drop(columns = ['cluster'])\n",
    "print(display(df_SOM_cluster_1))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_1, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328e0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soil_Organic_Matter Winter Combined Elements Results:\n",
    "#1.XGBoost Cluster 0 had good prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ec070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier Removal Summer, Parent Compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28288591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#Soil_Organic_Matter Cluster 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0[(df_SOM_cluster_0['Yield_kg_per_Ha'] > df_SOM_cluster_0['Yield_kg_per_Ha'].quantile(.05)) \\\n",
    "                                                               & (df_SOM_cluster_0['Yield_kg_per_Ha'] < df_SOM_cluster_0['Yield_kg_per_Ha'].quantile(.95))].reset_index(drop = True)\n",
    "\n",
    "print(display(df_SOM_cluster_0))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00328467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#Soil_Organic_Matter Cluster 1\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1[(df_SOM_cluster_1['Yield_kg_per_Ha'] > df_SOM_cluster_1['Yield_kg_per_Ha'].quantile(.05)) \\\n",
    "                                                               & (df_SOM_cluster_1['Yield_kg_per_Ha'] < df_SOM_cluster_1['Yield_kg_per_Ha'].quantile(.95))].reset_index(drop = True)\n",
    "\n",
    "print(display(df_SOM_cluster_1))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_1, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soil_Organic_Matter Summer Parent Compound, Outliers Removed Results:\n",
    "#1.No good prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e90bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier Removal Winter, Parent Compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791267b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Winter\n",
    "#Soil_Organic_Matter Cluster 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\\\n",
    "\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0[(df_SOM_cluster_0['Yield_kg_per_Ha'] > df_SOM_cluster_0['Yield_kg_per_Ha'].quantile(.05)) \\\n",
    "                                                               & (df_SOM_cluster_0['Yield_kg_per_Ha'] < df_SOM_cluster_0['Yield_kg_per_Ha'].quantile(.95))].reset_index(drop = True)\n",
    "\n",
    "print(display(df_SOM_cluster_0))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a1f1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Winter\n",
    "#Soil_Organic_Matter Cluster 1\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1[(df_SOM_cluster_1['Yield_kg_per_Ha'] > df_SOM_cluster_1['Yield_kg_per_Ha'].quantile(.05)) \\\n",
    "                                                               & (df_SOM_cluster_1['Yield_kg_per_Ha'] < df_SOM_cluster_1['Yield_kg_per_Ha'].quantile(.95))].reset_index(drop = True)\n",
    "\n",
    "print(display(df_SOM_cluster_1))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_1, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9334eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soil_Organic_Matter Winter Parent Compound, Outliers Removed Results:\n",
    "#1.No good prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5311184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier Removal Summer, Elements Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb4a72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#Soil_Organic_Matter Cluster 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_combined_elements.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0[(df_SOM_cluster_0['Yield_kg_per_Ha'] > df_SOM_cluster_0['Yield_kg_per_Ha'].quantile(.05)) \\\n",
    "                                                               & (df_SOM_cluster_0['Yield_kg_per_Ha'] < df_SOM_cluster_0['Yield_kg_per_Ha'].quantile(.95))].reset_index(drop = True)\n",
    "\n",
    "print(display(df_SOM_cluster_0))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e89ac6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#Soil_Organic_Matter Cluster 1\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_combined_elements.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1[(df_SOM_cluster_1['Yield_kg_per_Ha'] > df_SOM_cluster_1['Yield_kg_per_Ha'].quantile(.05)) \\\n",
    "                                                               & (df_SOM_cluster_1['Yield_kg_per_Ha'] < df_SOM_cluster_1['Yield_kg_per_Ha'].quantile(.95))].reset_index(drop = True)\n",
    "\n",
    "print(display(df_SOM_cluster_1))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_1, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e2abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soil_Organic_Matter Summer Parent Compound, Outliers Removed Results:\n",
    "#1.No good prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b28875",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier Removal Winter, Elements Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1ad797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Winter\n",
    "#Soil_Organic_Matter Cluster 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0[(df_SOM_cluster_0['Yield_kg_per_Ha'] > df_SOM_cluster_0['Yield_kg_per_Ha'].quantile(.05)) \\\n",
    "                                                               & (df_SOM_cluster_0['Yield_kg_per_Ha'] < df_SOM_cluster_0['Yield_kg_per_Ha'].quantile(.95))].reset_index(drop = True)\n",
    "\n",
    "print(display(df_SOM_cluster_0))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d07e783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Winter\n",
    "#Soil_Organic_Matter Cluster 1\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1[(df_SOM_cluster_1['Yield_kg_per_Ha'] > df_SOM_cluster_1['Yield_kg_per_Ha'].quantile(.05)) \\\n",
    "                                                               & (df_SOM_cluster_1['Yield_kg_per_Ha'] < df_SOM_cluster_1['Yield_kg_per_Ha'].quantile(.95))].reset_index(drop = True)\n",
    "\n",
    "print(display(df_SOM_cluster_1))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_1, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soil_Organic_Matter Winter Parent Compound, Outliers Removed Results:\n",
    "#1.No good prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bebcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of Fertilizer Applications Scatterplots and Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d883c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fertilizer applications vs. Yield, summer and winter\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(df['Crop_Protection_Application_Doses'], df['Yield_kg_per_Ha'])\n",
    "plt.xlabel('Crop Protection Application Doses')\n",
    "plt.ylabel('Yield (kg per ha)')\n",
    "plt.title('Crop Protection vs. Yield (Summer)')\n",
    "plt.show()\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(df['Crop_Protection_Application_Doses'], df['Yield_kg_per_Ha'])\n",
    "plt.xlabel('Crop Protection Application Doses')\n",
    "plt.ylabel('Yield (kg per ha)')\n",
    "plt.title('Crop Protection vs. Yield (Winter)')\n",
    "#Fertilizer applications vs. Yield (Summer, SOM Cluster 0 and 1)plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fertilizer applications vs. Yield (Summer, SOM Cluster 0 and 1)\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(df_SOM_cluster_0['Crop_Protection_Application_Doses'], df_SOM_cluster_0['Yield_kg_per_Ha'])\n",
    "plt.xlabel('Crop Protection Application Doses')\n",
    "plt.ylabel('Yield (kg per ha)')\n",
    "plt.title('Crop Protection vs. Yield (SOM Cluster 0, Summer)')\n",
    "plt.show()\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(df_SOM_cluster_1['Crop_Protection_Application_Doses'], df_SOM_cluster_1['Yield_kg_per_Ha'])\n",
    "plt.xlabel('Crop Protection Application Doses')\n",
    "plt.ylabel('Yield (kg per ha)')\n",
    "plt.title('Crop Protection vs. Yield (SOM Cluster 1, Summer)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f5b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fertilizer applications vs. Yield (Winter, SOM Cluster 0 and 1)\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(df_SOM_cluster_0['Crop_Protection_Application_Doses'], df_SOM_cluster_0['Yield_kg_per_Ha'])\n",
    "plt.xlabel('Crop Protection Application Doses')\n",
    "plt.ylabel('Yield (kg per ha)')\n",
    "plt.title('Crop Protection vs. Yield (SOM Cluster 0, Winter)')\n",
    "plt.show()\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(df_SOM_cluster_1['Crop_Protection_Application_Doses'], df_SOM_cluster_1['Yield_kg_per_Ha'])\n",
    "plt.xlabel('Crop Protection Application Doses')\n",
    "plt.ylabel('Yield (kg per ha)')\n",
    "plt.title('Crop Protection vs. Yield (SOM Cluster 1, Winter)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efde16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summer\n",
    "#Elbow method Crop Protection\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "sum_of_squared_distances = []\n",
    "for k in range(1,11):\n",
    "    kmeans = KMeans(n_clusters = k)\n",
    "    kmeans.fit(df['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "    sum_of_squared_distances.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1,11), sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('Num Clusters')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3de824b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#Crop Protection Cluster 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_crop_protection_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_crop_protection_cluster_0 = df_crop_protection_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "print(display(df_crop_protection_cluster_0))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f596a5d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#Crop Protection Cluster 1\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_crop_protection_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_crop_protection_cluster_1 = df_crop_protection_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "print(display(df_crop_protection_cluster_1))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_1, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c080fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crop Protection Summer Parent Compound:\n",
    "#1.XGBoost good prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e8bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Winter\n",
    "#Elbow method Crop Protection\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "sum_of_squared_distances = []\n",
    "for k in range(1,11):\n",
    "    kmeans = KMeans(n_clusters = k)\n",
    "    kmeans.fit(df['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "    sum_of_squared_distances.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1,11), sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('Num Clusters')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f3231",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Winter\n",
    "#Crop Protection Cluster 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_crop_protection_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_crop_protection_cluster_0 = df_crop_protection_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "print(display(df_crop_protection_cluster_0))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_crop_protection_cluster_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724956ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Winter\n",
    "#Crop Protection Cluster 1\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_crop_protection_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_crop_protection_cluster_1 = df_crop_protection_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "print(display(df_crop_protection_cluster_1))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_crop_protection_cluster_1, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crop Protection Winter Parent Compound:\n",
    "#1.No good prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb725e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summer\n",
    "#SOM Cluster 0, Crop Protection Application Doses Clustering\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "sum_of_squared_distances = []\n",
    "for k in range(1,11):\n",
    "    kmeans = KMeans(n_clusters = k)\n",
    "    kmeans.fit(df_SOM_cluster_0['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "    sum_of_squared_distances.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1,11), sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('Num Clusters')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d0add",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#SOM Cluster 0, Crop Protection Cluster 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df_SOM_cluster_0['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "df_SOM_cluster_0['cluster'] = kmeans.labels_\n",
    "\n",
    "df_SOM_cluster_0_crop_protection_cluster_0 = df_SOM_cluster_0[df_SOM_cluster_0['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0_crop_protection_cluster_0 = df_SOM_cluster_0_crop_protection_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "print(display(df_SOM_cluster_0_crop_protection_cluster_0))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_0_crop_protection_cluster_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b36847",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#SOM Cluster 0, Crop Protection Cluster 1\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df_SOM_cluster_0['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "df_SOM_cluster_0['cluster'] = kmeans.labels_\n",
    "\n",
    "df_SOM_cluster_0_crop_protection_cluster_1 = df_SOM_cluster_0[df_SOM_cluster_0['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_0_crop_protection_cluster_1 = df_SOM_cluster_0_crop_protection_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "print(display(df_SOM_cluster_0_crop_protection_cluster_1))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_0_crop_protection_cluster_1, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf3ba03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#SOM Cluster 1, Crop Protection Cluster 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df_SOM_cluster_1['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "df_SOM_cluster_1['cluster'] = kmeans.labels_\n",
    "\n",
    "df_SOM_cluster_1_crop_protection_cluster_0 = df_SOM_cluster_1[df_SOM_cluster_1['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_1_crop_protection_cluster_0 = df_SOM_cluster_1_crop_protection_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "print(display(df_SOM_cluster_1_crop_protection_cluster_0))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_1_crop_protection_cluster_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4ec14a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Summer\n",
    "#SOM Cluster 1, Crop Protection Cluster 1\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_summer_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df_SOM_cluster_1['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "df_SOM_cluster_1['cluster'] = kmeans.labels_\n",
    "\n",
    "df_SOM_cluster_1_crop_protection_cluster_1 = df_SOM_cluster_1[df_SOM_cluster_1['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1_crop_protection_cluster_1 = df_SOM_cluster_1_crop_protection_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "print(display(df_SOM_cluster_1_crop_protection_cluster_1))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_1_crop_protection_cluster_1, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019c9595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Winter\n",
    "#SOM Cluster 0, Crop Protection Application Doses Clustering\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "sum_of_squared_distances = []\n",
    "for k in range(1,11):\n",
    "    kmeans = KMeans(n_clusters = k)\n",
    "    kmeans.fit(df_SOM_cluster_0['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "    sum_of_squared_distances.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1,11), sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('Num Clusters')\n",
    "plt.ylabel('Sum of Squared Distances')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7275494",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Winter\n",
    "#SOM Cluster 0, Crop Protection Cluster 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df_SOM_cluster_0['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "df_SOM_cluster_0['cluster'] = kmeans.labels_\n",
    "\n",
    "df_SOM_cluster_0_crop_protection_cluster_0 = df_SOM_cluster_0[df_SOM_cluster_0['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0_crop_protection_cluster_0 = df_SOM_cluster_0_crop_protection_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "print(display(df_SOM_cluster_0_crop_protection_cluster_0))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_0_crop_protection_cluster_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee27c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Winter\n",
    "#SOM Cluster 0, Crop Protection Cluster 1\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_0 = df[df['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_0 = df_SOM_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df_SOM_cluster_0['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "df_SOM_cluster_0['cluster'] = kmeans.labels_\n",
    "\n",
    "df_SOM_cluster_0_crop_protection_cluster_1 = df_SOM_cluster_0[df_SOM_cluster_0['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_0_crop_protection_cluster_1 = df_SOM_cluster_0_crop_protection_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "print(display(df_SOM_cluster_0_crop_protection_cluster_1))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_0_crop_protection_cluster_1, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e11f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Winter\n",
    "#SOM Cluster 1, Crop Protection Cluster 0\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df_SOM_cluster_1['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "df_SOM_cluster_1['cluster'] = kmeans.labels_\n",
    "\n",
    "df_SOM_cluster_1_crop_protection_cluster_0 = df_SOM_cluster_1[df_SOM_cluster_1['cluster'] == 0].reset_index(drop = True)\n",
    "df_SOM_cluster_1_crop_protection_cluster_0 = df_SOM_cluster_1_crop_protection_cluster_0.drop(columns = ['cluster'])\n",
    "\n",
    "print(display(df_SOM_cluster_1_crop_protection_cluster_0))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_1_crop_protection_cluster_0, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6df063",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Winter\n",
    "#SOM Cluster 1, Crop Protection Cluster 1\n",
    "\n",
    "df = pd.read_csv('/mnt/Datasets/df_3_27_23_winter_parent_compounds.csv').drop(columns = 'Unnamed: 0')\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df['Soil_Organic_Matter'].values.reshape(-1,1))\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "df = df.drop(columns = ['CO2_kg_per_Ha'])\n",
    "\n",
    "df_SOM_cluster_1 = df[df['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1 = df_SOM_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(df_SOM_cluster_1['Crop_Protection_Application_Doses'].values.reshape(-1,1))\n",
    "df_SOM_cluster_1['cluster'] = kmeans.labels_\n",
    "\n",
    "df_SOM_cluster_1_crop_protection_cluster_1 = df_SOM_cluster_1[df_SOM_cluster_1['cluster'] == 1].reset_index(drop = True)\n",
    "df_SOM_cluster_1_crop_protection_cluster_1 = df_SOM_cluster_1_crop_protection_cluster_1.drop(columns = ['cluster'])\n",
    "\n",
    "print(display(df_SOM_cluster_1_crop_protection_cluster_1))\n",
    "\n",
    "train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(df_SOM_cluster_1_crop_protection_cluster_1, test_size = 0.2, random_state = 60)\n",
    "\n",
    "X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = standard_scaler_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_X = PowerTransformer(standardize = True).fit(X_train_Yield_kg_per_ha)\n",
    "X_train_Yield_kg_per_ha = power_transform_X.transform(X_train_Yield_kg_per_ha)\n",
    "\n",
    "X_test_Yield_kg_per_ha = standard_scaler_X.transform(X_test_Yield_kg_per_ha)\n",
    "X_test_Yield_kg_per_ha = power_transform_X.transform(X_test_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "mean_Yield_kg_per_ha = y_train_Yield_kg_per_ha.mean()\n",
    "\n",
    "y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "\n",
    "standard_scaler_y = StandardScaler().fit(np.array(y_train_Yield_kg_per_ha))\n",
    "\n",
    "y_train_Yield_kg_per_ha = standard_scaler_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "power_transform_y = PowerTransformer(standardize = False).fit(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_train_Yield_kg_per_ha = power_transform_y.transform(y_train_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = standard_scaler_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "y_test_Yield_kg_per_ha = power_transform_y.transform(y_test_Yield_kg_per_ha)\n",
    "\n",
    "kfolds = KFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "model_names = ['OLS', 'Lasso', 'Ridge', 'ElasticNet', 'SVR', 'GBR', 'XGBoost']\n",
    "models = [linear_model.LinearRegression(), \\\n",
    "            LassoCV(max_iter = int(1e7), alphas = alphas2, random_state = 42, cv = kfolds), \\\n",
    "                  RidgeCV(alphas = alphas_alt, cv = kfolds), \\\n",
    "                  ElasticNetCV(max_iter = int(1e7), alphas = e_alphas, cv = kfolds, l1_ratio = e_l1ratio), \\\n",
    "                  SVR(C = 20, epsilon = 0.008, gamma = 0.0003), \\\n",
    "                  GradientBoostingRegressor(n_estimators = 5000, learning_rate = 0.05, max_depth = 4, max_features = 'sqrt', min_samples_leaf = 15, \\\n",
    "                                            min_samples_split = 10, loss = 'huber', random_state = 42), \\\n",
    "                  XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                               colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "         ]\n",
    "\n",
    "fitted_models = []\n",
    "Test_MAE_models = []\n",
    "Test_RMSE_models = []\n",
    "Test_R2_models = []\n",
    "Test_mape_models = []\n",
    "Test_errors = []\n",
    "\n",
    "for model in models:\n",
    "    fitted_models.append(model.fit(X_train_Yield_kg_per_ha, y_train_Yield_kg_per_ha))\n",
    "    inv_transform_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[models.index(model)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))                                             \n",
    "    Test_MAE_models.append(mae(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_RMSE_models.append(rmse(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_R2_models.append(r2(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_mape_models.append(mape(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    Test_errors.append(errors(inv_transform_y_actuals, inv_transformed_preds))\n",
    "    plt.figure(figsize = (8,5))\n",
    "    plt.hist(np.sqrt((inv_transform_y_actuals - inv_transformed_preds)**2))\n",
    "    plt.xlabel('Absolute Errors')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Absolute Errors')\n",
    "    plt.show()\n",
    "    \n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    print('MAE on test data: ' + str(Test_MAE_models[model_names.index(model_name)]))\n",
    "    print('RMSE on test data: ' + str(Test_RMSE_models[model_names.index(model_name)]))\n",
    "    print('R squared on test data: ' + str(Test_R2_models[model_names.index(model_name)]))\n",
    "    print('MAPE on test data: ' + str(Test_mape_models[model_names.index(model_name)]))\n",
    "    inv_transformed_y_actuals = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(y_test_Yield_kg_per_ha).reshape(-1, 1))\n",
    "    inv_transformed_preds = standard_scaler_y.inverse_transform(power_transform_y.inverse_transform(fitted_models[model_names.index(model_name)].predict(X_test_Yield_kg_per_ha).reshape(-1,1)))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axhline(y=mean_Yield_kg_per_ha, color='r', linestyle='-', label = 'Mean Actual Target = ' + str(int(mean_Yield_kg_per_ha)))\n",
    "    ax.scatter(inv_transformed_y_actuals, inv_transformed_preds)\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    plt.xlabel('Actual Target')\n",
    "    plt.ylabel('Predicted Target')\n",
    "    plt.title(model_name + ' (Target: Yield kg per ha)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "for i in range(len(fitted_models)):\n",
    "    feature_names = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha']).columns\n",
    "\n",
    "    result = permutation_importance(\n",
    "        fitted_models[i], X_test_Yield_kg_per_ha, y_test_Yield_kg_per_ha, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "\n",
    "    model_importances = pd.Series(result.importances_mean, index = feature_names)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    model_importances.plot.bar(yerr = result.importances_std, ax = ax)\n",
    "    ax.set_title(\"Feature importances using permutation on full model (\" + str(model_names[i]) + ')')\n",
    "    ax.set_ylabel(\"Mean Accuracy decrease\")\n",
    "    plt.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22751667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3948e96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379c2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc470e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e4d327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36f80d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
