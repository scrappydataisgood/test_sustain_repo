{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2f58422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.22.0-py2.py3-none-any.whl (1.4 MB)\n",
      "     |████████████████████████████████| 1.4 MB 30.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.2.1 in /opt/conda/lib/python3.8/site-packages (from mlxtend) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /opt/conda/lib/python3.8/site-packages (from mlxtend) (1.21.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from mlxtend) (3.4.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /opt/conda/lib/python3.8/site-packages (from mlxtend) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from mlxtend) (51.1.2.post20210112)\n",
      "Collecting scikit-learn>=1.0.2\n",
      "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "     |████████████████████████████████| 9.8 MB 98.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.24.2 in /opt/conda/lib/python3.8/site-packages (from mlxtend) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.0.0->mlxtend) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.24.2->mlxtend) (2021.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=1.0.2->mlxtend) (2.1.0)\n",
      "Collecting joblib>=0.13.2\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     |████████████████████████████████| 297 kB 119.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.15.0)\n",
      "Installing collected packages: joblib, scikit-learn, mlxtend\n",
      "Successfully installed joblib-1.2.0 mlxtend-0.22.0 scikit-learn-1.2.2\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "     |████████████████████████████████| 2.0 MB 29.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn!=0.22.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from lightgbm) (1.2.2)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.8/site-packages (from lightgbm) (0.36.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from lightgbm) (1.21.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from lightgbm) (1.6.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.5\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.5-py3-none-manylinux2014_x86_64.whl (200.3 MB)\n",
      "     |████████████████████████████████| 200.3 MB 27 kB/s               \n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from xgboost) (1.21.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from xgboost) (1.6.0)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.5\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend --user\n",
    "!pip install lightgbm --user\n",
    "!pip install xgboost --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d126ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy as sp\n",
    "import math\n",
    "import random\n",
    "import seaborn as sn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew  # for some statistics\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import sklearn.linear_model as linear_model\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a535487",
   "metadata": {},
   "source": [
    "# Importing the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2a05e4",
   "metadata": {},
   "source": [
    "## Model Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43217682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(np.mean((y - y_pred)**2))\n",
    "\n",
    "def mae(y, y_pred):\n",
    "    return np.mean(np.absolute(np.subtract(y, y_pred)))\n",
    "\n",
    "def r2(y, y_pred):\n",
    "    return 1 - np.sum((y - y_pred)**2)/np.sum((y - np.mean(y))**2)\n",
    "\n",
    "def mape(y, y_pred):\n",
    "    return (np.mean(np.divide(np.absolute(np.subtract(y,y_pred)), y))*100)\n",
    "\n",
    "def errors(y, y_pred):\n",
    "    return np.absolute(y - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55bb62a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset generated from wet_yield_feature_outlier_filtering_and_transformation_prediction\n",
    "#Winter, subsetted by features to be more normal\n",
    "df_winter = pd.read_csv('/mnt/ETL/Dataset/prescription_dataset.csv').drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbf445e",
   "metadata": {},
   "source": [
    "## Using a Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9578463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictorWithScalars:\n",
    "    \n",
    "    def __init__(self, predictor, X_scalar, X_transformer, y_scalar, y_transformer):\n",
    "        self.predictor = predictor\n",
    "        self.X_scalar = X_scalar\n",
    "        self.X_transformer = X_transformer\n",
    "        self.y_scalar = y_scalar\n",
    "        self.y_transformer = y_transformer\n",
    "    \n",
    "    def transform_X(self, X):\n",
    "        transformed_X = self.X_transformer.transform(self.X_scalar.transform(X))\n",
    "        return transformed_X\n",
    "    \n",
    "    def transform_y(self, y):\n",
    "        transformed_y = self.y_transformer.transform(self.y_scalar.transform(y))\n",
    "        return transformed_y\n",
    "\n",
    "    def predict(self, X):\n",
    "        transformed_X = self.X_transformer.transform(self.X_scalar.transform(X))\n",
    "        transformed_y_preds = self.predictor.predict(transformed_X).reshape(-1,1)\n",
    "        inverse_transformed_y_preds = self.y_scalar.inverse_transform(self.y_transformer.inverse_transform(transformed_y_preds))\n",
    "        return inverse_transformed_y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3a1e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dataset, outlier_removal_lower_percentile, seed):\n",
    "    \n",
    "    dataset = dataset[(dataset['Yield_kg_per_Ha'] > dataset['Yield_kg_per_Ha'].quantile(outlier_removal_lower_percentile)) \\\n",
    "                                                                   & (dataset['Yield_kg_per_Ha'] < dataset['Yield_kg_per_Ha'].quantile(1-outlier_removal_lower_percentile))].reset_index(drop = True)\n",
    "\n",
    "    train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(dataset, test_size = 0.18, random_state = seed)\n",
    "\n",
    "    X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "    X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "    y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "    y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "    mean_Yield_kg_per_ha = np.mean(y_train_Yield_kg_per_ha)\n",
    "\n",
    "    standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "    power_transform_X = PowerTransformer(standardize = True).fit(standard_scaler_X.transform(X_train_Yield_kg_per_ha))\n",
    "\n",
    "    standard_scaler_y = StandardScaler().fit(y_train_Yield_kg_per_ha)\n",
    "    power_transform_y = PowerTransformer(standardize = True).fit(standard_scaler_y.transform(y_train_Yield_kg_per_ha))\n",
    "\n",
    "    xgboost = XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                                              colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "\n",
    "    predictorScaler = PredictorWithScalars(xgboost, standard_scaler_X, power_transform_X, standard_scaler_y, power_transform_y)\n",
    "    predictorScaler.predictor = predictorScaler.predictor.fit(predictorScaler.transform_X(X_train_Yield_kg_per_ha), predictorScaler.transform_y(y_train_Yield_kg_per_ha))\n",
    "    \n",
    "    return predictorScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c48cf3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(df_winter_combined_parents_final_test_set, model_build_dict):\n",
    "    \n",
    "    y_preds = np.zeros((len(df_winter_combined_parents_final_test_set), len(model_build_dict)))\n",
    "    \n",
    "    for i in range(len(model_build_dict)):\n",
    "\n",
    "        X_df_winter_combined_parents_final_test_set = df_winter_combined_parents_final_test_set.drop(columns = ['Yield_kg_per_Ha'])\n",
    "        y_df_winter_combined_parents_final_test_set = np.array(df_winter_combined_parents_final_test_set['Yield_kg_per_Ha']).reshape(-1,1)\n",
    "        y_preds[:,i] = model_build_dict.get(i).predict(X_df_winter_combined_parents_final_test_set)[:,0]\n",
    "        \n",
    "    final_preds = np.mean(y_preds, axis = 1).reshape(-1,1)\n",
    "    mean_abs_error = mean_absolute_error(y_df_winter_combined_parents_final_test_set, final_preds)\n",
    "    root_mean_sq_error = np.sqrt(mean_squared_error(y_df_winter_combined_parents_final_test_set, final_preds))\n",
    "    r_sq = r2_score(y_df_winter_combined_parents_final_test_set, final_preds)\n",
    "    \n",
    "    return mean_abs_error, root_mean_sq_error, r_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bfaae51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:09] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:00:12] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:00:16] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:00:19] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:00:23] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:00:27] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:00:30] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:00:34] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:00:38] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:00:41] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:00:45] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:00:48] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:00:52] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:00:56] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:00:59] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:01:03] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:01:06] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:01:10] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:01:13] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:01:17] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:01:21] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:01:24] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:01:28] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:01:31] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:01:35] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_models</th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r_squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1553.396785</td>\n",
       "      <td>2068.561054</td>\n",
       "      <td>0.110055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1432.505590</td>\n",
       "      <td>1750.588206</td>\n",
       "      <td>-0.023193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1379.817376</td>\n",
       "      <td>1724.864342</td>\n",
       "      <td>0.210138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1426.293594</td>\n",
       "      <td>1793.255533</td>\n",
       "      <td>0.321461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1477.515086</td>\n",
       "      <td>1874.862198</td>\n",
       "      <td>0.218457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  num_models          mae         rmse  r_squared\n",
       "0          5  1553.396785  2068.561054   0.110055\n",
       "0          5  1432.505590  1750.588206  -0.023193\n",
       "0          5  1379.817376  1724.864342   0.210138\n",
       "0          5  1426.293594  1793.255533   0.321461\n",
       "0          5  1477.515086  1874.862198   0.218457"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "df_winter_combined_parents = pd.read_csv('/mnt/ETL/Dataset/prescription_dataset.csv').drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "num_seeds_list = [5, 5, 5, 5, 5]\n",
    "\n",
    "random_state_list = random.sample(range(1000), len(num_seeds_list))\n",
    "\n",
    "results_collection_df = pd.DataFrame(columns = ['num_models', 'mae', 'rmse', 'r_squared'])\n",
    "\n",
    "for i,num_seeds in enumerate(num_seeds_list):\n",
    "    \n",
    "    df_winter_combined_parents_temp = df_winter_combined_parents.sample(frac = 1, random_state = random_state_list[i]).reset_index(drop = True)\n",
    "    df_winter_combined_parents_final_test_set = df_winter_combined_parents_temp[:57]\n",
    "    df_winter_combined_parents_temp = df_winter_combined_parents_temp[57:].reset_index(drop = True)\n",
    "    \n",
    "    seed_list = random.sample(range(1000), num_seeds)\n",
    "    \n",
    "    model_build_dict = {}\n",
    "    \n",
    "    for i,seed in enumerate(seed_list):\n",
    "        model_build_dict.update({i: build_model(df_winter_combined_parents_temp, 0, seed)})\n",
    "    \n",
    "    eval_model_temp = eval_model(df_winter_combined_parents_final_test_set, model_build_dict)\n",
    "    row = pd.DataFrame({'num_models': [num_seeds], 'mae': [eval_model_temp[0]], 'rmse': [eval_model_temp[1]], 'r_squared': [eval_model_temp[2]]})\n",
    "    \n",
    "    results_collection_df = pd.concat([results_collection_df, row], axis = 0)\n",
    "\n",
    "print(display(results_collection_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32eda68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4590f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7401ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winter_combined_parents = pd.read_csv('/mnt/ETL/Dataset/prescription_dataset.csv').drop(columns = ['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73c40b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictorWithScalars:\n",
    "    \n",
    "    def __init__(self, predictor, X_scalar, X_transformer, y_scalar, y_transformer):\n",
    "        self.predictor = predictor\n",
    "        self.X_scalar = X_scalar\n",
    "        self.X_transformer = X_transformer\n",
    "        self.y_scalar = y_scalar\n",
    "        self.y_transformer = y_transformer\n",
    "    \n",
    "    def transform_X(self, X):\n",
    "        transformed_X = self.X_transformer.transform(self.X_scalar.transform(X))\n",
    "        return transformed_X\n",
    "    \n",
    "    def transform_y(self, y):\n",
    "        transformed_y = self.y_transformer.transform(self.y_scalar.transform(y))\n",
    "        return transformed_y\n",
    "\n",
    "    def predict(self, X):\n",
    "        transformed_X = self.X_transformer.transform(self.X_scalar.transform(X))\n",
    "        transformed_y_preds = self.predictor.predict(transformed_X).reshape(-1,1)\n",
    "        inverse_transformed_y_preds = self.y_scalar.inverse_transform(self.y_transformer.inverse_transform(transformed_y_preds))\n",
    "        return inverse_transformed_y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f61cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(dataset, outlier_removal_lower_percentile, seed):\n",
    "    \n",
    "    dataset = dataset[(dataset['Yield_kg_per_Ha'] > dataset['Yield_kg_per_Ha'].quantile(outlier_removal_lower_percentile)) \\\n",
    "                                                                   & (dataset['Yield_kg_per_Ha'] < dataset['Yield_kg_per_Ha'].quantile(1-outlier_removal_lower_percentile))].reset_index(drop = True)\n",
    "\n",
    "    train_Yield_kg_per_ha, test_Yield_kg_per_ha = train_test_split(dataset, test_size = 0.18, random_state = seed)\n",
    "\n",
    "    X_train_Yield_kg_per_ha = train_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "    X_test_Yield_kg_per_ha = test_Yield_kg_per_ha.drop(columns = ['Yield_kg_per_Ha'])\n",
    "\n",
    "    y_train_Yield_kg_per_ha = np.array(train_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "    y_test_Yield_kg_per_ha = np.array(test_Yield_kg_per_ha['Yield_kg_per_Ha']).reshape(-1, 1)\n",
    "    mean_Yield_kg_per_ha = np.mean(y_train_Yield_kg_per_ha)\n",
    "\n",
    "    standard_scaler_X = StandardScaler().fit(X_train_Yield_kg_per_ha)\n",
    "    power_transform_X = PowerTransformer(standardize = True).fit(standard_scaler_X.transform(X_train_Yield_kg_per_ha))\n",
    "\n",
    "    standard_scaler_y = StandardScaler().fit(y_train_Yield_kg_per_ha)\n",
    "    power_transform_y = PowerTransformer(standardize = True).fit(standard_scaler_y.transform(y_train_Yield_kg_per_ha))\n",
    "\n",
    "    xgboost = XGBRegressor(learning_rate = 0.005, n_estimators = 10000, max_depth = 3, min_child_weight = 0, gamma = 0, subsample = 0.7, \\\n",
    "                                              colsample_bytree = 0.7, objective = 'reg:linear', nthread = -1, scale_pos_weight = 1, seed = 27, reg_alpha = 0.00006)\n",
    "\n",
    "    predictorScaler = PredictorWithScalars(xgboost, standard_scaler_X, power_transform_X, standard_scaler_y, power_transform_y)\n",
    "    predictorScaler.predictor = predictorScaler.predictor.fit(predictorScaler.transform_X(X_train_Yield_kg_per_ha), predictorScaler.transform_y(y_train_Yield_kg_per_ha))\n",
    "    \n",
    "    return predictorScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b02b4571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:00:28] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:00:32] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:00:36] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:00:40] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:00:43] WARNING: ../src/objective/regression_obj.cu:213: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# from sklearn.externals import joblib\n",
    "\n",
    "random.seed(10)\n",
    "random_state_list1 = random.sample(range(1000), 5)\n",
    "\n",
    "random.seed(11)\n",
    "random_state_list2 = random.sample(range(1000), 5)\n",
    "\n",
    "pickle.dump(df_winter_combined_parents, open('/mnt/ETL/Dataset/prescription_dataset.csv', 'wb'))\n",
    "\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents.sample(frac = 1, random_state = random_state_list1[0]).reset_index(drop = True)\n",
    "df_winter_combined_parents_final_test_set = df_winter_combined_parents_temp[:57]\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents_temp[57:].reset_index(drop = True)\n",
    "\n",
    "predictor_scaler1 = build_model(df_winter_combined_parents_temp, 0, random_state_list2[0])\n",
    "pickle.dump(predictor_scaler1.X_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Scalar_1.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler1.y_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_Scalar_1.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler1.X_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Transformer_1.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler1.y_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_transformer_1.pkl', \"wb\"))\n",
    "pickle.dump(predictor_scaler1.predictor, open(\"/mnt/ETL/pkl_predictors_scalars_transformers/predictor_111.pkl\", \"wb\"))\n",
    "\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents.sample(frac = 1, random_state = random_state_list1[0]).reset_index(drop = True)\n",
    "df_winter_combined_parents_final_test_set = df_winter_combined_parents_temp[:57]\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents_temp[57:].reset_index(drop = True)\n",
    "predictor_scaler2 = build_model(df_winter_combined_parents_temp, 0, random_state_list2[1])\n",
    "pickle.dump(predictor_scaler2.X_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Scalar_2.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler2.y_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_Scalar_2.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler2.X_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Transformer_2.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler2.y_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_transformer_2.pkl', \"wb\"))\n",
    "pickle.dump(predictor_scaler2.predictor, open(\"/mnt/ETL/pkl_predictors_scalars_transformers/predictor_222.pkl\", \"wb\"))\n",
    "\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents.sample(frac = 1, random_state = random_state_list1[0]).reset_index(drop = True)\n",
    "df_winter_combined_parents_final_test_set = df_winter_combined_parents_temp[:57]\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents_temp[57:].reset_index(drop = True)\n",
    "predictor_scaler3 = build_model(df_winter_combined_parents_temp, 0, random_state_list2[2])\n",
    "pickle.dump(predictor_scaler3.X_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Scalar_3.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler3.y_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_Scalar_3.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler3.X_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Transformer_3.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler3.y_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_transformer_3.pkl', \"wb\"))\n",
    "pickle.dump(predictor_scaler3.predictor, open(\"/mnt/ETL/pkl_predictors_scalars_transformers/predictor_333.pkl\", \"wb\"))\n",
    "\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents.sample(frac = 1, random_state = random_state_list1[0]).reset_index(drop = True)\n",
    "df_winter_combined_parents_final_test_set = df_winter_combined_parents_temp[:57]\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents_temp[57:].reset_index(drop = True)\n",
    "predictor_scaler4 = build_model(df_winter_combined_parents_temp, 0, random_state_list2[3])\n",
    "pickle.dump(predictor_scaler4.X_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Scalar_4.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler4.y_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_Scalar_4.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler4.X_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Transformer_4.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler4.y_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_transformer_4.pkl', \"wb\"))\n",
    "pickle.dump(predictor_scaler4.predictor, open(\"/mnt/ETL/pkl_predictors_scalars_transformers/predictor_444.pkl\", \"wb\"))\n",
    "\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents.sample(frac = 1, random_state = random_state_list1[0]).reset_index(drop = True)\n",
    "df_winter_combined_parents_final_test_set = df_winter_combined_parents_temp[:57]\n",
    "df_winter_combined_parents_temp = df_winter_combined_parents_temp[57:].reset_index(drop = True)\n",
    "predictor_scaler5 = build_model(df_winter_combined_parents_temp, 0, random_state_list2[4])\n",
    "pickle.dump(predictor_scaler5.X_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Scalar_5.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler5.y_scalar, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_Scalar_5.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler5.X_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/X_Transformer_5.pkl', 'wb'))\n",
    "pickle.dump(predictor_scaler5.y_transformer, open('/mnt/ETL/pkl_predictors_scalars_transformers/y_transformer_5.pkl', \"wb\"))\n",
    "pickle.dump(predictor_scaler5.predictor, open(\"/mnt/ETL/pkl_predictors_scalars_transformers/predictor_555.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553b32f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
